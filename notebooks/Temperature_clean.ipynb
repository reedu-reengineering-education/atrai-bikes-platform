{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34218805-b510-4a5b-89ad-a61860647649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "initial_data = pd.read_csv ('combined_data_21_01_2025.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95b394ad-5edb-409e-83e9-7966895db42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'device_id' and count the number of rows for each device\n",
    "device_counts = initial_data.groupby('device_id').size()\n",
    "\n",
    "# Filter out device_ids with fewer than 10 data entries\n",
    "valid_device_ids = device_counts[device_counts >= 10].index\n",
    "\n",
    "# Filter the original DataFrame to keep only rows with valid device_ids\n",
    "initial_data = initial_data[initial_data['device_id'].isin(valid_device_ids)]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "#print(initial_data)\n",
    "#print (device_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a670a60d-dda9-4754-b9b0-30e0f3f5a466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import transform\n",
    "import pyproj\n",
    "from shapely import wkt\n",
    "\n",
    "# Function to get coordinates of the building address\n",
    "def get_coordinates(address):\n",
    "    geolocator = Nominatim(user_agent=\"Buffer_Creation\")\n",
    "    location = geolocator.geocode(address)\n",
    "    if location:\n",
    "        return location.latitude, location.longitude\n",
    "    else:\n",
    "        raise ValueError(f\"Address '{address}' not found.\")\n",
    "\n",
    "# Function to filter out rows within the buffer\n",
    "def filter_within_buffer(initial_data_w, address, radius_m):\n",
    "    # Get the building's coordinates (latitude, longitude)\n",
    "    building_lat, building_lon = get_coordinates(address)\n",
    "    \n",
    "    # Create a Point (building location)\n",
    "    building_point = Point(building_lon, building_lat)\n",
    "    \n",
    "    # Set up the projection for UTM (meter-based projection)\n",
    "    proj_wgs84 = pyproj.CRS('EPSG:4326')  # WGS84 (lat/lon)\n",
    "    proj_utm = pyproj.CRS('EPSG:32632')  # UTM zone 32N (adjust for your location)\n",
    "\n",
    "    # Transform the building point to UTM (to get meter-based coordinates)\n",
    "    transformer = pyproj.Transformer.from_crs(proj_wgs84, proj_utm, always_xy=True)\n",
    "    building_point_utm = transform(transformer.transform, building_point)\n",
    "\n",
    "    # Create a buffer in meters (UTM system uses meters)\n",
    "    building_buffer = building_point_utm.buffer(radius_m)\n",
    "\n",
    "    # Ensure the geometry column is in the correct format (Shapely geometries)\n",
    "    def safe_wkt_load(x):\n",
    "        if isinstance(x, str):  # Only try to load WKT strings\n",
    "            try:\n",
    "                return wkt.loads(x)\n",
    "            except:\n",
    "                return None  # Return None if the WKT is invalid\n",
    "        return None  # Return None for non-string entries\n",
    "\n",
    "    # Apply the safe WKT loading function\n",
    "    initial_data_w['geometry'] = initial_data_w['geometry'].apply(safe_wkt_load)\n",
    "\n",
    "    # Reproject the geometry column to UTM\n",
    "    initial_data_w['geometry_utm'] = initial_data_w['geometry'].apply(lambda point: transform(transformer.transform, point) if point is not None else None)\n",
    "    \n",
    "    # Filter rows where the UTM geometry is outside the buffer\n",
    "    filtered_data = initial_data_w[~initial_data_w['geometry_utm'].apply(lambda point: building_buffer.contains(point) if point is not None else False)]\n",
    "\n",
    "    # Drop the 'geometry_utm' column as it's no longer needed\n",
    "    filtered_data = filtered_data.drop(columns=['geometry_utm'])\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "# Example usage\n",
    "address = \"Von-Steuben-Straße 21, 48143 Münster\"\n",
    "initial_data_w = initial_data.copy(deep=True)  # Explicitly create a deep copy of the DataFrame\n",
    "\n",
    "# Apply the filter to get bike data within the buffer\n",
    "atrai_bike_data = filter_within_buffer(initial_data_w, address, radius_m=15)\n",
    "\n",
    "#atrai_bike_data.to_csv('atrai_bike_data_ohne_Büro_21_01_25.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcb8bd08-ec75-471f-980e-8eecd5c3abe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Münster Temperature Heatmap saved as Muenster_Temperature_Heatmap.html\n",
      "Spring Temperature Heatmap saved as Spring_Temperature_Heatmap_MS.html\n",
      "Summer Temperature Heatmap saved as Summer_Temperature_Heatmap_MS.html\n",
      "Autumn Temperature Heatmap saved as Autumn_Temperature_Heatmap_MS.html\n",
      "Winter Temperature Heatmap saved as Winter_Temperature_Heatmap_MS.html\n"
     ]
    }
   ],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "# Step 1: Convert 'createdAt' to datetime\n",
    "atrai_bike_data['createdAt'] = pd.to_datetime(atrai_bike_data['createdAt'])\n",
    "\n",
    "# Step 2: Add a column for meteorological seasons based on the month\n",
    "def get_season(month):\n",
    "    if month in [3, 4, 5]:  # Spring\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:  # Summer\n",
    "        return 'Summer'\n",
    "    elif month in [9, 10, 11]:  # Autumn\n",
    "        return 'Autumn'\n",
    "    else:  # Winter\n",
    "        return 'Winter'\n",
    "\n",
    "atrai_bike_data['Season'] = atrai_bike_data['createdAt'].dt.month.apply(get_season)\n",
    "\n",
    "# Step 3: Sort data by 'Season', 'device_id', and 'createdAt' for better performance\n",
    "atrai_bike_data = atrai_bike_data.sort_values(by=['Season', 'device_id', 'createdAt'])\n",
    "\n",
    "# Step 4: Calculate the time difference between consecutive 'createdAt' values for each 'device_id'\n",
    "atrai_bike_data['time_diff'] = atrai_bike_data.groupby('device_id')['createdAt'].diff().dt.total_seconds()\n",
    "\n",
    "# Step 5: Calculate the total ride duration for each device_id\n",
    "total_ride_duration = atrai_bike_data.groupby('device_id')['time_diff'].cumsum().max()\n",
    "\n",
    "# Step 6: Filter out the first and last 60 seconds of each ride\n",
    "filtered_data = atrai_bike_data[\n",
    "    atrai_bike_data.groupby('device_id')['time_diff'].cumsum() > 60  # Remove first 60 seconds\n",
    "]\n",
    "filtered_data = filtered_data[\n",
    "    filtered_data.groupby('device_id')['time_diff'].cumsum() < (total_ride_duration - 60)  # Remove last 60 seconds\n",
    "]\n",
    "\n",
    "# Step 7: Add regional filtering option\n",
    "# Define latitude and longitude bounds for the region\n",
    "lat_min, lat_max = 51.8, 52.1  # Adjust these values for your region\n",
    "lng_min, lng_max = 7.5, 7.7    # Adjust these values for your region\n",
    "\n",
    "# Filter data to include only points within the region\n",
    "regional_filtered_data = filtered_data[\n",
    "    (filtered_data['lat'] >= lat_min) & (filtered_data['lat'] <= lat_max) &\n",
    "    (filtered_data['lng'] >= lng_min) & (filtered_data['lng'] <= lng_max)\n",
    "]\n",
    "\n",
    "# Step 8: Function to generate heatmap\n",
    "def create_heatmap(data, title=\"Heatmap\", file_name=\"Heatmap.html\"):\n",
    "    # Remove rows with missing temperature, latitude, or longitude data\n",
    "    heatmap_data_temp = data[['lat', 'lng', 'Temperature']].dropna(subset=['Temperature', 'lat', 'lng'])\n",
    "\n",
    "    # Prepare the heatmap data: [latitude, longitude, Temperature value]\n",
    "    heat_data_temp = heatmap_data_temp[['lat', 'lng', 'Temperature']].values\n",
    "\n",
    "    # Create the folium map centered around the region's average latitude and longitude\n",
    "    m_temp = folium.Map(location=[(lat_min + lat_max) / 2, (lng_min + lng_max) / 2], zoom_start=13)\n",
    "\n",
    "    # Create and add the heatmap to the map\n",
    "    HeatMap(heat_data_temp, radius=15, blur=15).add_to(m_temp)\n",
    "\n",
    "    # Save the map as an HTML file\n",
    "    m_temp.save(file_name)\n",
    "    print(f\"{title} saved as {file_name}\")\n",
    "\n",
    "    return m_temp\n",
    "\n",
    "# Step 9: Generate heatmap for the regional data\n",
    "regional_heatmap = create_heatmap(\n",
    "    regional_filtered_data, \n",
    "    title=\"Münster Temperature Heatmap\", \n",
    "    file_name=\"Muenster_Temperature_Heatmap.html\"\n",
    ")\n",
    "\n",
    "# Step 10: Generate seasonal heatmaps (optional)\n",
    "for season in ['Spring', 'Summer', 'Autumn', 'Winter']:\n",
    "    seasonal_data = regional_filtered_data[regional_filtered_data['Season'] == season]\n",
    "    create_heatmap(\n",
    "        seasonal_data,\n",
    "        title=f\"{season} Temperature Heatmap\",\n",
    "        file_name=f\"{season}_Temperature_Heatmap_MS.html\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1e8844-2b1b-4f97-af4f-81ff69ab9bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
